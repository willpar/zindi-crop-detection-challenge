{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate all features\n",
    "\n",
    "This notebook takes the extracted train and test datasets and transforms them into engineered feature datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to automatically reload all modules (if they've been externally edited)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.generate_features import (GenerateLocationFeatures,\n",
    "                                        GenerateVegIndexFeatures,\n",
    "                                        GenerateTimeDiffFeatures,\n",
    "                                        GenerateStatFeatures,\n",
    "                                        GenerateMeanDiffFeatures,\n",
    "                                        GenerateResizedImages,\n",
    "                                        ObjectToPixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_pickle('extracted_data/train_data.pkl')\n",
    "test_data = pd.read_pickle('extracted_data/test_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Location Features (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latitude and longitude of each field in the train set is used to fit a KMeans clustering algorithm, which divides the location of the fields into 'zones'. This fitted model then acts as a transformer to label each field with a zone number -- with the number of clusters specifying the number of zones (features generated for between 10-2000 zones in this example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_features = GenerateLocationFeatures().fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_features_train = location_features.transform(train_data, \n",
    "                                                    save = True, path = 'processed_data/train/location_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_features_test = location_features.transform(test_data, \n",
    "                                                    save = True, path = 'processed_data/test/location_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Veg Index Features (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain transformations of spectral bands may be used to accentuate the spectral response of green plants such that the characteristics of the vegetation may be measured, the background soil signal may be discounted, as well as atmospheric and topographic effects. A selection of these are calculated for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamparfitt/Dropbox/Home/Data Science/FarmDrop_4/modules/generate_features.py:139: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x[NIR_col].astype(np.int16) + x[RED_col].astype(np.int16))\n",
      "/Users/williamparfitt/Dropbox/Home/Data Science/FarmDrop_4/modules/generate_features.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  RVI = np.divide(x[NIR_col].astype(np.int16), x[RED_col].astype(np.int16))\n",
      "/Users/williamparfitt/Dropbox/Home/Data Science/FarmDrop_4/modules/generate_features.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  IPVI = x[NIR_col].astype(np.int16) / (x[NIR_col].astype(np.int16) + x[RED_col].astype(np.int16))\n",
      "/Users/williamparfitt/Dropbox/Home/Data Science/FarmDrop_4/modules/generate_features.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ARVI = (x[NIR_col].astype(np.int16) - RB) / (x[NIR_col].astype(np.int16) + RB)\n"
     ]
    }
   ],
   "source": [
    "vegindex_features_train = GenerateVegIndexFeatures().transform(train_data, \n",
    "                                                         save = True, path = 'processed_data/train/vegindex_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegindex_features_test = GenerateVegIndexFeatures().transform(test_data, \n",
    "                                                         save = True, path = 'processed_data/test/vegindex_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---> Merge into train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensures the following features are calculated with the previous features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(vegindex_features_train, on='Field_Id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(vegindex_features_test, on='Field_Id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate time difference features (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change in the appearance of a field over time is likely closely related to the crop type, as a result of seeding and growth cycles throughout the year. Intensity difference features are calculated between the seasons of the year in an attempt to highlight this time-series pattern in the absence of several years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamparfitt/Dropbox/Home/Data Science/FarmDrop_4/modules/generate_features.py:295: RuntimeWarning: invalid value encountered in true_divide\n",
      "  change = (x[new_col].astype(np.float32) - x[old_col].astype(np.float32)) / x[old_col].astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "timediff_features_train = GenerateTimeDiffFeatures().transform(train_data, \n",
    "                                                         save = True, path = 'processed_data/train/timediff_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timediff_features_test = GenerateTimeDiffFeatures().transform(test_data, \n",
    "                                                       save = True, path = 'processed_data/test/timediff_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---> Merge into train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensures the following features are calculated with the previous features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(timediff_features_train, on='Field_Id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(timediff_features_test, on='Field_Id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate statistical features (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, std, max and min pixel intensities are calculated for each image of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_features_train = GenerateStatFeatures().transform(train_data, \n",
    "                                                         save = True, path = 'processed_data/train/stat_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_features_test = GenerateStatFeatures().transform(test_data, \n",
    "                                                         save = True, path = 'processed_data/test/stat_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mean difference features (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deviation of a field from the 'typical' image for each crop may be a useful indicator of their similarity. The mean pixel value for each crop type in the training set is calculated, the difference between each pixel in an image and this mean is then determined for each field.\n",
    "\n",
    "Note: This takes a long time to run and will be ignored as they are currently unused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate resized images (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each field is a different size and shape, with the image represented by a numpy array of pixel intensities padded by zeros. In order to standardise these images for NN training, they are resized to common dimensions (32 x 32 in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_train = GenerateResizedImages().transform(train_data, \n",
    "                                                         save = True, path = 'processed_data/train/resized_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images_test = GenerateResizedImages().transform(test_data, \n",
    "                                                         save = True, path = 'processed_data/test/resized_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to pixels (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the pixel based models, the dataset is transformed from a set of image arrays to a set of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expand_to_pixels_train = ObjectToPixels().transform(train_data, \n",
    "                                                         save = True, path = 'processed_data/train/expanded_pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_to_pixels_test = ObjectToPixels().transform(test_data, \n",
    "                                                         save = True, path = 'processed_data/test/expanded_pixels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
