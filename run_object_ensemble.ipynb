{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Object-based ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method makes use of statistical and location features calculated for each field using an ensemble of linear (LogisticRegression), nearest-neighbours (KNN) and tree-based methods (RandomForest, ExtraTrees, XGBoost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Run this cell to automatically reload all modules (if they've been externally edited)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run this cell to silence warnings (not recommended!) Used here to silence LogReg convergence warning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.process_data import SelectFeatures, Scale, OneHot\n",
    "from modules.run_models import ModelEnsemble, make_submission\n",
    "from modules.metaclassifiers import UnweightedAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load processed feature datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('extracted_data/train_data.pkl')\n",
    "stat_features_train = pd.read_pickle('processed_data/train/stat_features.pkl')\n",
    "location_features_train = pd.read_pickle('processed_data/train/location_features.pkl')\n",
    "expanded_pixels_train = pd.read_pickle('processed_data/train/expanded_pixels.pkl')\n",
    "\n",
    "\n",
    "test_data = pd.read_pickle('extracted_data/test_data.pkl')\n",
    "stat_features_test = pd.read_pickle('processed_data/test/stat_features.pkl')\n",
    "location_features_test = pd.read_pickle('processed_data/test/location_features.pkl')\n",
    "expanded_pixels_test = pd.read_pickle('processed_data/test/expanded_pixels.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select statistical features for each spectral band including the calculated NDVI vegetative index, as well as location features with 200 zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected  617  columns \n",
      "Use .cols attribute to see all columns\n",
      "\n",
      "Selected  617  columns \n",
      "Use .cols attribute to see all columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf = SelectFeatures(keep_cols=['mean', 'std', 'max', 'min', 'location_200'], \n",
    "                    drop_cols=['diff', 'TCI', 'RVI', '_DVI', 'IPVI', 'ARVI', 'location_2000'])\n",
    "\n",
    "fit_A = sf.transform([train_data, stat_features_train, location_features_train])\n",
    "predict_A = sf.transform([test_data, stat_features_test, location_features_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Min-Max scale all numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling  616  columns \n",
      "Use .cols attribute to see all columns\n",
      "\n",
      "Scaling  616  columns \n",
      "Use .cols attribute to see all columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc = Scale(keep_cols=['B', 'NDVI']).fit(fit_A)\n",
    "\n",
    "fit_A = sc.transform(fit_A)\n",
    "predict_A = sc.transform(predict_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One-hot encode categorical location features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding  1  columns \n",
      "Use .cols attribute to see all columns\n",
      "\n",
      "Encoding  1  columns \n",
      "Use .cols attribute to see all columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oh = OneHot(keep_cols=['location_200']).fit(fit_A)\n",
    "\n",
    "fit_A = oh.transform(fit_A)\n",
    "predict_A = oh.transform(predict_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fill NaN with their mean column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_A = fit_A.fillna(fit_A.mean())\n",
    "predict_A = predict_A.fillna(fit_A.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0101_B05_max</th>\n",
       "      <th>0210_B11_min</th>\n",
       "      <th>0715_B07_mean</th>\n",
       "      <th>0131_B12_max</th>\n",
       "      <th>0131_B8A_std</th>\n",
       "      <th>0819_NDVI_std</th>\n",
       "      <th>0620_B8A_max</th>\n",
       "      <th>0620_B02_min</th>\n",
       "      <th>0715_B07_max</th>\n",
       "      <th>0715_B05_max</th>\n",
       "      <th>...</th>\n",
       "      <th>location_200_190</th>\n",
       "      <th>location_200_191</th>\n",
       "      <th>location_200_192</th>\n",
       "      <th>location_200_193</th>\n",
       "      <th>location_200_194</th>\n",
       "      <th>location_200_195</th>\n",
       "      <th>location_200_196</th>\n",
       "      <th>location_200_197</th>\n",
       "      <th>location_200_198</th>\n",
       "      <th>location_200_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.385355</td>\n",
       "      <td>0.447401</td>\n",
       "      <td>0.330374</td>\n",
       "      <td>0.414763</td>\n",
       "      <td>0.269055</td>\n",
       "      <td>0.071518</td>\n",
       "      <td>0.478680</td>\n",
       "      <td>0.717791</td>\n",
       "      <td>0.428621</td>\n",
       "      <td>0.475167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.343195</td>\n",
       "      <td>0.427027</td>\n",
       "      <td>0.658061</td>\n",
       "      <td>0.329805</td>\n",
       "      <td>0.243533</td>\n",
       "      <td>0.179315</td>\n",
       "      <td>0.769257</td>\n",
       "      <td>0.599864</td>\n",
       "      <td>0.678229</td>\n",
       "      <td>0.473424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.364152</td>\n",
       "      <td>0.402911</td>\n",
       "      <td>0.385792</td>\n",
       "      <td>0.245125</td>\n",
       "      <td>0.133185</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>0.528026</td>\n",
       "      <td>0.646898</td>\n",
       "      <td>0.466969</td>\n",
       "      <td>0.580017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.285996</td>\n",
       "      <td>0.393347</td>\n",
       "      <td>0.296498</td>\n",
       "      <td>0.317270</td>\n",
       "      <td>0.249262</td>\n",
       "      <td>0.092814</td>\n",
       "      <td>0.503611</td>\n",
       "      <td>0.656442</td>\n",
       "      <td>0.443612</td>\n",
       "      <td>0.458612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.348619</td>\n",
       "      <td>0.417672</td>\n",
       "      <td>0.527508</td>\n",
       "      <td>0.369081</td>\n",
       "      <td>0.163205</td>\n",
       "      <td>0.149857</td>\n",
       "      <td>0.693776</td>\n",
       "      <td>0.646217</td>\n",
       "      <td>0.578874</td>\n",
       "      <td>0.506245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0101_B05_max  0210_B11_min  0715_B07_mean  0131_B12_max  0131_B8A_std  \\\n",
       "0      0.385355      0.447401       0.330374      0.414763      0.269055   \n",
       "1      0.343195      0.427027       0.658061      0.329805      0.243533   \n",
       "2      0.364152      0.402911       0.385792      0.245125      0.133185   \n",
       "3      0.285996      0.393347       0.296498      0.317270      0.249262   \n",
       "4      0.348619      0.417672       0.527508      0.369081      0.163205   \n",
       "\n",
       "   0819_NDVI_std  0620_B8A_max  0620_B02_min  0715_B07_max  0715_B05_max  ...  \\\n",
       "0       0.071518      0.478680      0.717791      0.428621      0.475167  ...   \n",
       "1       0.179315      0.769257      0.599864      0.678229      0.473424  ...   \n",
       "2       0.067051      0.528026      0.646898      0.466969      0.580017  ...   \n",
       "3       0.092814      0.503611      0.656442      0.443612      0.458612  ...   \n",
       "4       0.149857      0.693776      0.646217      0.578874      0.506245  ...   \n",
       "\n",
       "   location_200_190  location_200_191  location_200_192  location_200_193  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   location_200_194  location_200_195  location_200_196  location_200_197  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   location_200_198  location_200_199  \n",
       "0               0.0               0.0  \n",
       "1               0.0               0.0  \n",
       "2               0.0               0.0  \n",
       "3               0.0               0.0  \n",
       "4               0.0               0.0  \n",
       "\n",
       "[5 rows x 817 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classifiers and metaclassifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a combination of linear, nearest-neighbour and tree-based models both for classification and model stacking. \n",
    "Note: UnweightedAv is a custom estimator which simply takes the combines the predictions by taking their (unweighted) average. A weighted average estimator was also tested, using Nelder-Mead weight optimisation but was prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "'LogReg': LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "'RandomForest': RandomForestClassifier(n_estimators = 1000),\n",
    "'KNN': KNeighborsClassifier(n_neighbors=100),\n",
    "'ExtraTrees': ExtraTreesClassifier(n_estimators = 1000),\n",
    "'XGB': XGBClassifier(silent=False, \n",
    "                    n_estimators=1000, learning_rate=0.3, \n",
    "                    scale_pos_weight=1, colsample_bytree = 0.4, subsample = 0.9, objective='multi:softprob', \n",
    "                    eval_metric='mlogloss', reg_alpha = 0.3, max_depth=6, gamma=5)}\n",
    "\n",
    "metaclassifiers = {\n",
    "'LogReg': LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "'RandomForest': RandomForestClassifier(n_estimators = 1000),\n",
    "'UnweightedAv': UnweightedAverage(n_classes=9)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifiers... \n",
      "\n",
      "Classifier                  Fold 1 Score             Fold 2 Score\n",
      "---------------------------------------------------------------------\n",
      "LogReg                          0.737                    0.743\n",
      "RandomForest                    0.821                    0.913\n",
      "KNN                             1.369                    1.527\n",
      "ExtraTrees                      0.830                    0.887\n",
      "XGB                             0.799                    0.863\n",
      "\n",
      "\n",
      "Fitting metaclassifiers... \n",
      "\n",
      "Meta-Classifier                 Score\n",
      "----------------------------------------------\n",
      "LogReg                          1.700                  \n",
      "RandomForest                    0.336                  \n",
      "UnweightedAv                    2.492                  \n",
      "\n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "ensemble_A = ModelEnsemble(clfs=classifiers, mclfs=metaclassifiers).fit(fit_A, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-fitting and predicting classifiers... \n",
      "\n",
      "Classifier                     Status\n",
      "----------------------------------------------\n",
      "LogReg                          Complete\n",
      "RandomForest                    Complete\n",
      "KNN                             Complete\n",
      "ExtraTrees                      Complete\n",
      "XGB                             Complete\n",
      "\n",
      "\n",
      "Predicting metaclassifiers... \n",
      "\n",
      "Meta-Classifier                 Status\n",
      "----------------------------------------------\n",
      "LogReg                          Complete\n",
      "RandomForest                    Complete\n",
      "UnweightedAv                    Complete\n",
      "\n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "predictions = ensemble_A.predict(predict_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(predictions, 'Ensemble_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
